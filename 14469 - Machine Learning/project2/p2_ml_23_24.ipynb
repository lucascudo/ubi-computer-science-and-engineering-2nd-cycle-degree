{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Consider the “MNIST” dataset, (in “csv” format) available at “Kaggle.com” (https://www.kaggle.com/datasets/oddrationale/mnist-in-csv). The “mnist_train csv” file contains the 60,000 training examples and labels. The “mnist_test.csv” contains 10,000 test examples and labels. Each row consists of 785 values: the first value is the label (a number from 0 to 9) and the remaining 784 values are the pixel values (a number from 0 to 255)."
      ],
      "metadata": {
        "id": "Yth1vepqOV8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess_data(data, normalization_function = lambda v: v/255.0):\n",
        "  labels = data.iloc[:, 0].values\n",
        "  images = normalization_function(data.iloc[:, 1:].values)\n",
        "  return images, labels\n",
        "\n",
        "# Load and preprocess the data\n",
        "train_data = pd.read_csv('mnist_train.csv')\n",
        "test_data = pd.read_csv('mnist_test.csv')\n",
        "train_images, train_labels = preprocess_data(train_data)\n",
        "test_images, test_labels = preprocess_data(test_data)\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdymsLAX5RG4",
        "outputId": "52bf97fa-a12f-4192-858a-ddea3ea2fdaa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 785)\n",
            "(10000, 785)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Develop and implement a “logistic_regression.py” script that contains a model able to distinguish between the “0”..”9” classes in this dataset."
      ],
      "metadata": {
        "id": "jvoUPBUD5V36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class RegularizedSoftmaxRegression:\n",
        "  def __init__(self, learning_rate=0.1, max_iter=1000, C=1, tol=0.0001):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = max_iter\n",
        "    self.tol = tol\n",
        "    self.lambda_ = 0.001 * (1.0 / C)\n",
        "    self.epsilon = 1e-9\n",
        "\n",
        "  def compute_loss(self, y_true, y_pred):\n",
        "    y_pred = y_pred.clip(min=self.epsilon, max=1 - self.epsilon)\n",
        "    loss = -np.mean(y_true * np.log(y_pred))\n",
        "    l2_regularization = (self.lambda_ / 2) * np.sum(np.square(self.weights))\n",
        "    return loss + l2_regularization\n",
        "\n",
        "  def one_hot_encode(self, labels):\n",
        "    labels = np.array(labels, dtype=int)\n",
        "    one_hot_encoded = np.zeros((len(labels), len(np.unique(labels))))\n",
        "    one_hot_encoded[np.arange(len(labels)), labels] = 1\n",
        "    return one_hot_encoded\n",
        "\n",
        "  def softmax(self, z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "  def predict_proba(self, X):\n",
        "    z = np.dot(X, self.weights) + self.bias\n",
        "    A = self.softmax(z)\n",
        "    return A\n",
        "\n",
        "  def fit(self, X, raw_y):\n",
        "    y = self.one_hot_encode(raw_y)\n",
        "    n_samples, n_features = X.shape\n",
        "    n_classes = y.shape[1]\n",
        "    self.weights = np.zeros((n_features, n_classes))\n",
        "    self.bias = np.zeros(n_classes)\n",
        "    self.losses = []\n",
        "    for _ in range(self.epochs):\n",
        "      A = self.predict_proba(X)\n",
        "      self.losses.append(self.compute_loss(y, A))\n",
        "      dz = A - y\n",
        "      dw = (1 / n_samples) * np.dot(X.T, dz) + self.lambda_ * self.weights\n",
        "      db = (1 / n_samples) * np.sum(dz, axis=0)\n",
        "      self.weights -= self.learning_rate * dw\n",
        "      self.bias -= self.learning_rate * db\n",
        "      # Early stopping condition\n",
        "      if len(self.losses) > 10:\n",
        "        relative_improvement = (self.losses[-11] - self.losses[-1]) / (self.losses[-11] + self.epsilon)\n",
        "        if relative_improvement < self.tol:\n",
        "          break\n",
        "    return self.weights, self.bias, self.losses\n",
        "\n",
        "  def predict(self, X):\n",
        "    A = self.predict_proba(X)\n",
        "    y_predicted_cls = np.argmax(A, axis=1)\n",
        "    return y_predicted_cls"
      ],
      "metadata": {
        "id": "z626D7v5OWD9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def train_and_evaluate(model, train_images, train_labels, test_images=test_images, test_labels=test_labels):\n",
        "  model.fit(train_images, train_labels)\n",
        "  pred_labels = model.predict(test_images)\n",
        "  return accuracy_score(pred_labels, test_labels)\n",
        "\n",
        "%time print(\"Accuracy: \", train_and_evaluate(RegularizedSoftmaxRegression(), train_images, train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sgoMxlDmPmL",
        "outputId": "3b26769e-3afd-4ce3-e6fa-0563c4828764"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.8992\n",
            "CPU times: user 5min 3s, sys: 25.6 s, total: 5min 29s\n",
            "Wall time: 3min 32s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Repeating training and evaluation process, but using sklearn's LogisticRegression"
      ],
      "metadata": {
        "id": "qqPyhx3p7zF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "%time print(\"Accuracy: \", train_and_evaluate(LogisticRegression(max_iter=1000), train_images, train_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFdRaPZh8KzR",
        "outputId": "57ebfb7f-5655-4d48-eb60-0393c7e22f9b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.9256\n",
            "CPU times: user 8min 53s, sys: 33.4 s, total: 9min 27s\n",
            "Wall time: 5min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avoiding memory and time consumption issues"
      ],
      "metadata": {
        "id": "i_JU2ZZ78PhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "model_classes = {\n",
        "    \"MyLogisticRegression\": RegularizedSoftmaxRegression,\n",
        "    \"ScikitLogisticRegression\": LogisticRegression\n",
        "}\n",
        "\n",
        "for factor in [0.1, 0.2]: # Using subsets of 10 and 20 percent of the training data\n",
        "  subset_size = int(len(train_images) * factor)\n",
        "  for model_name in model_classes.keys():\n",
        "      print(f\"{model_name} with {subset_size} samples:\")\n",
        "      start_time = time.time()\n",
        "      accuracy = train_and_evaluate(model_classes[model_name](max_iter=1000), train_images[:subset_size], train_labels[:subset_size])\n",
        "      execution_time = time.time() - start_time\n",
        "      print(\"Accuracy: \", accuracy)\n",
        "      print(f\"Execution Time: {int(execution_time)}s\")\n",
        "      print(f\"Time-Normalized Accuracy: {accuracy / execution_time} \\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pbbZCkk-ZNu",
        "outputId": "66ab5fde-c779-40e2-fdfd-214820cab6d0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyLogisticRegression with 6000 samples:\n",
            "Accuracy:  0.8924\n",
            "Execution Time: 28s\n",
            "Time-Normalized Accuracy: 0.03138009968836341 \n",
            "\n",
            "ScikitLogisticRegression with 6000 samples:\n",
            "Accuracy:  0.8968\n",
            "Execution Time: 17s\n",
            "Time-Normalized Accuracy: 0.05167572200487719 \n",
            "\n",
            "MyLogisticRegression with 12000 samples:\n",
            "Accuracy:  0.8929\n",
            "Execution Time: 55s\n",
            "Time-Normalized Accuracy: 0.016032313524142926 \n",
            "\n",
            "ScikitLogisticRegression with 12000 samples:\n",
            "Accuracy:  0.9083\n",
            "Execution Time: 34s\n",
            "Time-Normalized Accuracy: 0.026530489585009687 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adopting a 10% subset for now on!"
      ],
      "metadata": {
        "id": "2lKdkQwG5InO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "subset_size = int(len(train_images) * 0.1)\n",
        "train_images_subset = train_images[:subset_size]\n",
        "train_labels_subset = train_labels[:subset_size]\n",
        "\n",
        "print(train_images_subset.shape)\n",
        "print(train_labels_subset.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mv56IHhL154",
        "outputId": "2dda575b-8833-4f95-95ec-64b107902d3a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6000, 784)\n",
            "(6000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "a) different feature normalization strategies: \\\\\n",
        "• Min-max \\\\\n",
        "• Z-score"
      ],
      "metadata": {
        "id": "qgTIIrbaMLec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def z_score_normalizer(values):\n",
        "  mean = values.mean(axis=0)\n",
        "  std = values.std(axis=0)\n",
        "  return (values - mean) / (std + 1e-7) #Adding a small value to avoid division by zero\n",
        "\n",
        "z_scored_train_images_subset, _ = preprocess_data(train_data[:subset_size], z_score_normalizer)\n",
        "z_scored_test_images, _ = preprocess_data(test_data, z_score_normalizer)\n",
        "\n",
        "for model_name in model_classes.keys():\n",
        "  accuracy = train_and_evaluate(model_classes[model_name](max_iter=1000), train_images_subset, train_labels_subset)\n",
        "  print(f\"{model_name} (Min-max normalization): {accuracy}\")\n",
        "  accuracy = train_and_evaluate(model_classes[model_name](max_iter=1000), z_scored_train_images_subset, train_labels_subset, z_scored_test_images)\n",
        "  print(f\"{model_name} (z-score normalization): {accuracy}\")"
      ],
      "metadata": {
        "id": "D-VR2_abMVue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f4019a2-8aca-40f1-86ef-62cf0b9885e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyLogisticRegression (Min-max normalization): 0.8924\n",
            "MyLogisticRegression (z-score normalization): 0.9029\n",
            "ScikitLogisticRegression (Min-max normalization): 0.8968\n",
            "ScikitLogisticRegression (z-score normalization): 0.8897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b) different model regularization values."
      ],
      "metadata": {
        "id": "G77yI8mFMXZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regularization_transformers = {\n",
        "    \"Stronger\": 0.01,\n",
        "    \"Strong\": 0.1,\n",
        "    \"Default\": 1,\n",
        "    \"Weak\": 10.0,\n",
        "    \"Weaker\": 100.0\n",
        "}\n",
        "\n",
        "print(\"MyLogisticRegression with z-score normalization on:\")\n",
        "for regularization_transformer_key in regularization_transformers:\n",
        "  model = RegularizedSoftmaxRegression(C=regularization_transformers[regularization_transformer_key])\n",
        "  accuracy = train_and_evaluate(model, z_scored_train_images_subset, train_labels_subset, z_scored_test_images)\n",
        "  print(f\"{regularization_transformer_key} regularization: {accuracy}\")\n",
        "\n",
        "print(\"\\nScikitLogisticRegression with min-max normalization on:\")\n",
        "for regularization_transformer_key in regularization_transformers:\n",
        "  model = LogisticRegression(max_iter=1000, C=regularization_transformers[regularization_transformer_key])\n",
        "  accuracy = train_and_evaluate(model, train_images_subset, train_labels_subset)\n",
        "  print(f\"{regularization_transformer_key} regularization: {accuracy}\")"
      ],
      "metadata": {
        "id": "aWL0HGnnMaM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e88ee6-7b09-4a84-8b68-cfe869be7fde"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyLogisticRegression with z-score normalization on:\n",
            "Stronger regularization: 0.8616\n",
            "Strong regularization: 0.8906\n",
            "Default regularization: 0.9029\n",
            "Weak regularization: 0.9022\n",
            "Weaker regularization: 0.9023\n",
            "\n",
            "ScikitLogisticRegression with min-max normalization on:\n",
            "Stronger regularization: 0.8945\n",
            "Strong regularization: 0.9067\n",
            "Default regularization: 0.8968\n",
            "Weak regularization: 0.8858\n",
            "Weaker regularization: 0.8799\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "c) different stopping criteria and learning rates for your model."
      ],
      "metadata": {
        "id": "SJXM5GtjMakf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterias = {\n",
        "    \"default\": {\n",
        "        \"tol\": 0.0001,\n",
        "        \"max_iter\": 1000\n",
        "    },\n",
        "    \"stopping sooner\": {\n",
        "        \"tol\": 0.001,\n",
        "        \"max_iter\": 500\n",
        "    },\n",
        "    \"trainning longer\": {\n",
        "        \"tol\": 0.00001,\n",
        "        \"max_iter\": 2000\n",
        "    }\n",
        "}\n",
        "\n",
        "for key in criterias.keys():\n",
        "  my_model = RegularizedSoftmaxRegression(max_iter=criterias[key][\"max_iter\"], tol=criterias[key][\"tol\"])\n",
        "  my_accuracy = train_and_evaluate(my_model, z_scored_train_images_subset, train_labels_subset, z_scored_test_images)\n",
        "  print(f\"MyLogisticRegression with z-score normalization ({key}): {my_accuracy}\")\n",
        "  sk_model = LogisticRegression(C=0.1, max_iter=criterias[key][\"max_iter\"], tol=criterias[key][\"tol\"])\n",
        "  sk_accuracy = train_and_evaluate(sk_model, train_images_subset, train_labels_subset)\n",
        "  print(f\"ScikitLogisticRegression with min-max normalization ({key}): {sk_accuracy}\\n\")"
      ],
      "metadata": {
        "id": "oXBGxSnPMa4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f2ac58d-2b9a-4cc4-fee1-a4ad4cb4f17d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyLogisticRegression with z-score normalization (default): 0.9029\n",
            "ScikitLogisticRegression with min-max normalization (default): 0.9067\n",
            "\n",
            "MyLogisticRegression with z-score normalization (stopping sooner): 0.9031\n",
            "ScikitLogisticRegression with min-max normalization (stopping sooner): 0.9067\n",
            "\n",
            "MyLogisticRegression with z-score normalization (trainning longer): 0.9029\n",
            "ScikitLogisticRegression with min-max normalization (trainning longer): 0.9067\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.01, 0.1, 1.0]\n",
        "for learning_rate in learning_rates:\n",
        "  model = RegularizedSoftmaxRegression(learning_rate=learning_rate)\n",
        "  accuracy = train_and_evaluate(model, z_scored_train_images_subset, train_labels_subset, z_scored_test_images)\n",
        "  print(f\"MyLogisticRegression with learning rate of {learning_rate}: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiWplOvusek-",
        "outputId": "d223d3f4-8a0f-4e79-db5d-ac75bc109825"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyLogisticRegression with learning rate of 0.01: 0.8957\n",
            "MyLogisticRegression with learning rate of 0.1: 0.9029\n",
            "MyLogisticRegression with learning rate of 1.0: 0.903\n"
          ]
        }
      ]
    }
  ]
}